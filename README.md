方案主要有四个方面内容：（1）数据读取与预处理 （2）特征工程 （3）模型训练及融合 （4）后处理

**1.数据读取与预处理**;

（1）通过read_csv进行读取比赛训练集和测试集，经过缺失值，重复值处理后合并训练集和测试集，以便后续进行特征工程。

**2.特征工程**

（1）根据相关性系数删除冗余特征

（2）对预定义的feat_one_hot列表中的特征进行One-Hot编码

（3）通过简单的特征组合，交叉衍生新特征

（4）通过log函数进行特征缩放

（5）内存压缩，降低运行性能。

**3.模型训练及融合**

（1）通过K折交叉验证（KFold）来增强模型的泛化能力。每轮交叉验证中，数据被随机分割成训练集和验证集，用于训练LightGBM模型并评估其性能。模型参数包括使用梯度提升决策树（GBDT）、多分类目标、accuracy作为评估指标等。训练过程中，通过早停法避免过拟合，并记录每轮的性能评估。最终，通过多轮交叉验证的结果，可以评估模型的稳定性和性能。

（2）为了进一步提高模型性能，本方案通过硬投票融合方式对多个预测结果result进行融合。


**后期改进方向**

（1）从数据层面，通过该领域相关文献和工作，挖掘出更加具有区分度、表达性更强的特征，以及采取更有效的方式处理样本不平衡。

（2）从模型层面，一是从参数方面优化，通过超参框架找出一组最优的参数，提高模型准率率。二是通过修改模型结构，训练策略，进一步提高总体性能。